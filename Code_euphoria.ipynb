{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uU8TE6MvgKLJ"
   },
   "source": [
    "## Dacon 14회 KB 금융문자 분석 모델링 경진대회\n",
    "### euphoria , 2020.01.17\n",
    "### Summary\n",
    "1. Text Cleaning and make Bi-gram\n",
    "2. Data Sampling\n",
    "3. Text Preprocessing with tf.keras.Tokenizer and pad_sequences\n",
    "4. train Bi-Directional LSTM model\n",
    "5. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wnBsm5b820wD"
   },
   "source": [
    "## 1. 라이브러리 및 데이터\n",
    "### 1-1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOY7wsx_LKCj"
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "# text tokenizing\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "# modeling\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, SpatialDropout1D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ap8IpUX5CYJ"
   },
   "source": [
    "### 1-2. Settings for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2unTANeu49W0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90838570\n"
     ]
    }
   ],
   "source": [
    "sd = random.randint(0,99999999)\n",
    "print(sd)\n",
    "\n",
    "np.random.seed(sd)\n",
    "random.seed(sd)\n",
    "os.environ['PYTHONHASHSEED']=str(sd)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(sd)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7vMYQkt7r8m"
   },
   "source": [
    "### 1-3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "2arA7qSIgtGt",
    "outputId": "45b56187-2e83-41de-df2b-aae624526578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295945, 4)\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('/content/gdrive/My Drive/Colab Notebooks/smishing/') \n",
    "train = pd.read_csv('0_Data/train.csv')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GR6rYpgo3ubq"
   },
   "source": [
    "## 2. 데이터 전처리\n",
    "### 2-1. Data Cleaning\n",
    "- Mecab을 이용하여 텍스트를 정제합니다.\n",
    "    - 영문은 소문자화하고 한글, 영문 제외 모두 제거하였습니다.\n",
    "    - 영문 중 xxx 등으로 비식별처리된 것은 모두 제거하였습니다.\n",
    "- Bi-gram을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDG7diik76t8"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    '''\n",
    "    args: text list that wants to tokenize\n",
    "    return: bigram list\n",
    "    '''\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', 'null'] # 제거: 불용어, 한글 영문 외 문자, XXX 등 비식별처리된 문자\n",
    "    tokenizer = Mecab()\n",
    "    bigram_list = []\n",
    "    for text in text_list:\n",
    "        txt = re.sub('[^가-힣a-z]',' ',text.lower())\n",
    "        txt = re.sub('x{1,}',' ',txt)\n",
    "        token = tokenizer.morphs(txt)  # tokenizing\n",
    "        token = [t for t in token if t not in stopwords or type(t)!= float] # text cleaning\n",
    "        bigram = [token[i]+'.'+token[i+1] for i in range(len(token)-1)]  # bi-gram\n",
    "        bigram_list.append(' '.join(bigram))\n",
    "    return bigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bigram'] = text_preprocessing(train.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBqAVONG-PBo"
   },
   "source": [
    "### 2-2. Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-gbA3iJ0neA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 277242, 1: 18703})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train['smishing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdFKHQqh0va_"
   },
   "source": [
    "- Counter({0: 277242, 1: 18703})으로 6.31975535994864%의 비율만이 스미싱 문자임을 알 수 있습니다.\n",
    "- 즉, 데이터 불균형 문제(Data Imbalance Problem)가 발생하였습니다.\n",
    "- 따라서 데이터를 혼합하여 샘플링하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itgYwhhGBzzA"
   },
   "outputs": [],
   "source": [
    "def train_data_sampling(train, seed=1234, a=3, b=3):\n",
    "    '''\n",
    "    Args: train data, seed number, a(under sampling), b(over sampling)\n",
    "    Return: sampling index\n",
    "    '''\n",
    "    train_nsm_idx=list(train[train['smishing']==0].index)\n",
    "    train_sm_idx=list(train[train['smishing']==1].index)\n",
    "    random.seed(seed)\n",
    "    train_nsm_idx = random.sample(train_nsm_idx, k=18703*a)\n",
    "    random.seed(seed)\n",
    "    train_sm_idx = random.choices(train_sm_idx, k=18703*b)\n",
    "    train_idx = train_nsm_idx + train_sm_idx\n",
    "    print(train_idx[:5])\n",
    "    random.shuffle(train_idx)\n",
    "    print(train_idx[:5])\n",
    "    return train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "kvFIOD9HBY3T",
    "outputId": "7306fa4f-a836-44d2-81a6-c76e1238c9e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206864, 218560, 111768, 152524, 170588]\n",
      "[25559, 185452, 293634, 175839, 247866]\n",
      "(93515, 6)\n"
     ]
    }
   ],
   "source": [
    "trn_idx = train_data_sampling(train, seed=sd, a=3, b=2)\n",
    "df_train = train.iloc[trn_idx].reset_index(drop=True)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNLLwnt1bCm-"
   },
   "source": [
    "### 2-3. text pre-processing\n",
    "- 모델을 학습하기 위해 텍스트 데이터를 시퀀스 데이터로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pYUYKgCEpj8"
   },
   "outputs": [],
   "source": [
    "def save_tokenizer(tokenizer, mname):\n",
    "    with open('1_Model/'+mname+'.pickle', 'wb') as f:\n",
    "        pickle.dump(tokenizer, f, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtzQUkXSB4oC"
   },
   "outputs": [],
   "source": [
    "def text2sequence(train_text, max_len=1000):\n",
    "    '''\n",
    "    transform text to sequence\n",
    "    Args: text of train data, max length(for word embedding)\n",
    "    Return: train data(for modeling), vocabulary size\n",
    "    '''\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_text)\n",
    "    save_tokenizer(tokenizer, 'tokenizer') # save trained tokenizer\n",
    "    train_X_seq = tokenizer.texts_to_sequences(train_text)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    print('vocab size: ', vocab_size)\n",
    "    X_train = pad_sequences(train_X_seq, maxlen=max_len)\n",
    "    return X_train, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "XuGsuVebewK3",
    "outputId": "3763a0c3-d2a0-49e9-d556-483309eafbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  22614\n",
      "vocab size:  22614\n",
      "(93515, 660) (93515,)\n"
     ]
    }
   ],
   "source": [
    "train_y = df_train['smishing']\n",
    "train_X, vocab_size = text2sequence(df_train['bigram'], max_len=660)\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ua9JfvszX407"
   },
   "source": [
    "## 3. 탐색적 자료 분석 (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onDiYpU31eJ5"
   },
   "source": [
    "- 위의 max_len을 정하기 위해 EDA를 하여 적당한 len을 결정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([len(x.split()) for x in train['bigram']]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNsXkyJMhmhB"
   },
   "source": [
    "## 4. 변수 선택 및 모델 구축\n",
    "### Build Model\n",
    "- 모델 평가 지표는 AUC입니다.\n",
    "- 모델은 Bi-LSTM (Bi-Directional Long Short Term Memory)을 사용하였습니다.\n",
    "- 텍스트는 Bi-gram을 sequence로 변환한 데이터로 학습하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JY49FyLN39Lm"
   },
   "outputs": [],
   "source": [
    "auc_ = 0\n",
    "def auc_score(y_true, y_pred):\n",
    "    global auc_\n",
    "    try:\n",
    "        auc_ = roc_auc_score( y_true, y_pred, average='macro', sample_weight = None).astype('float32')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return auc_\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    score = tf.py_func( lambda y_true, y_pred : auc_score(y_true, y_pred) , [y_true, y_pred], 'float32', stateful = False, name = 'sklearnAUC' )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kCh0a2eLFxj"
   },
   "outputs": [],
   "source": [
    "def BiLSTM(vocab_size, max_len=1000):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length = max_len))\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='tanh', kernel_regularizer = regularizers.l2(0.001)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpJnBvgClEhA"
   },
   "outputs": [],
   "source": [
    "def model_save(model, mname):\n",
    "    model_json = model.to_json()\n",
    "    with open('1_Model/'+mname+'.json', 'w') as json_file : \n",
    "        json_file.write(model_json)\n",
    "    model.save_weights('1_Model/'+mname+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqwq_3Rmh5e2"
   },
   "source": [
    "## 5. 모델 학습 및 검증\n",
    "- 모델을 학습합니다.\n",
    "- EarlyStopping으로 과도한 학습을 하지 않고 적당한 score에 도달하면 조기종료 할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "fULSvCnRmfep",
    "outputId": "1e552434-38a9-4262-beb3-01597ef773f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TIME:  2020-01-17T12:10:54.752534\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 660, 128)          2894592   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 660, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,001,729\n",
      "Trainable params: 3,001,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 65460 samples, validate on 28055 samples\n",
      "Epoch 1/50\n",
      "65460/65460 [==============================] - 2077s 32ms/sample - loss: 0.0547 - auc: 0.9966 - val_loss: 0.0060 - val_auc: 1.0000\n",
      "Epoch 2/50\n",
      "65460/65460 [==============================] - 2064s 32ms/sample - loss: 0.0034 - auc: 1.0000 - val_loss: 0.0028 - val_auc: 1.0000\n",
      "Epoch 3/50\n",
      "65460/65460 [==============================] - 2060s 31ms/sample - loss: 0.0054 - auc: 0.9999 - val_loss: 0.0035 - val_auc: 1.0000\n",
      "Epoch 4/50\n",
      "65460/65460 [==============================] - 2063s 32ms/sample - loss: 0.0026 - auc: 1.0000 - val_loss: 0.0054 - val_auc: 1.0000\n",
      "Epoch 5/50\n",
      "65460/65460 [==============================] - 2070s 32ms/sample - loss: 0.0022 - auc: 1.0000 - val_loss: 0.0019 - val_auc: 1.0000\n",
      "Epoch 6/50\n",
      "65460/65460 [==============================] - 2041s 31ms/sample - loss: 0.0043 - auc: 0.9999 - val_loss: 0.0332 - val_auc: 0.9999\n",
      "Epoch 7/50\n",
      "65460/65460 [==============================] - 1903s 29ms/sample - loss: 0.0072 - auc: 0.9999 - val_loss: 0.0026 - val_auc: 1.0000\n",
      "Epoch 8/50\n",
      "65460/65460 [==============================] - 1860s 28ms/sample - loss: 0.0014 - auc: 1.0000 - val_loss: 0.0017 - val_auc: 1.0000\n",
      "Epoch 9/50\n",
      "65460/65460 [==============================] - 1845s 28ms/sample - loss: 0.0014 - auc: 1.0000 - val_loss: 0.0026 - val_auc: 1.0000\n",
      "Epoch 10/50\n",
      "65460/65460 [==============================] - 1833s 28ms/sample - loss: 0.0014 - auc: 1.0000 - val_loss: 0.0019 - val_auc: 1.0000\n",
      "Epoch 11/50\n",
      "55040/65460 [========================>.....] - ETA: 4:28 - loss: 8.2333e-04 - auc: 1.0000"
     ]
    }
   ],
   "source": [
    "print('START TIME: ', datetime.now().isoformat())\n",
    "model = BiLSTM(vocab_size, max_len=660)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.00001)\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=128, validation_split=0.3, callbacks=[early_stopping])\n",
    "\n",
    "model_save(model, 'model') # save trained model\n",
    "print('END TIME: ', datetime.now().isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGAGjhDqzn9a"
   },
   "source": [
    "## 6. 예측\n",
    "- 위에서 훈련한 tokenizer와 model을 load하고 test set으로 predict 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5__SCgYPVPqS"
   },
   "outputs": [],
   "source": [
    "def text2sequence_test(tokenizer, test_text, max_len=1000):\n",
    "    test_seq = tokenizer.texts_to_sequences(test_text)\n",
    "    X_test = pad_sequences(test_seq, maxlen=max_len)\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nBWa9Njzyzg"
   },
   "outputs": [],
   "source": [
    "def get_prediction(test_file_path):\n",
    "    '''\n",
    "    Args: String\n",
    "    Return: Pandas DataFrame    \n",
    "    '''\n",
    "    \n",
    "    '''1. load test dataset'''\n",
    "    test = pd.read_csv(test_file_path)\n",
    "    \n",
    "    '''2. load model and tokenizer'''\n",
    "    with open('1_Model/tokenizer.pickle', 'rb') as f:\n",
    "        tokenizer_test = pickle.load(f)\n",
    "    with open('1_Model/model.json', 'r') as ff:\n",
    "        json_model = ff.read()\n",
    "    model_test = model_from_json(json_model)\n",
    "    model_test.load_weights('1_Model/model.h5')\n",
    "    \n",
    "    '''3. test data preprocessing'''\n",
    "    test['bigram'] = text_preprocessing(test.text)\n",
    "    test_X = text2sequence_test(tokenizer_test, test['bigram'], max_len=660)\n",
    "    \n",
    "    model_test.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc])\n",
    "\n",
    "    '''4. prediction'''\n",
    "    y_pred = model_test.predict(test_X, batch_size=128)\n",
    "    \n",
    "    '''5. make submission'''\n",
    "    test['smishing'] = y_pred\n",
    "    submission = test[['id','smishing']]\n",
    "    #submission.to_csv('submission.csv',index=False)\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrDeLGrtz0gn"
   },
   "outputs": [],
   "source": [
    "y_pred = get_prediction('0_Data/public_test.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Code_euphoria.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
