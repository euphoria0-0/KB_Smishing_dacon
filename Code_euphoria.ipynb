{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_euphoria.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/euphoria96/KB_Smishing_dacon/blob/master/Code_euphoria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU8TE6MvgKLJ",
        "colab_type": "text"
      },
      "source": [
        "## Dacon 14회 KB 금융문자 분석 모델링 경진대회\n",
        "### euphoria\n",
        "### 2020년 1월 17일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnBsm5b820wD",
        "colab_type": "text"
      },
      "source": [
        "## 1. 라이브러리 및 데이터\n",
        "### 1-1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOY7wsx_LKCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessing\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "# text tokenizing\n",
        "import re\n",
        "from konlpy.tag import Mecab\n",
        "# modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, SpatialDropout1D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ap8IpUX5CYJ",
        "colab_type": "text"
      },
      "source": [
        "### 1-2. Settings for reproducible results\n",
        "> ref: https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2unTANeu49W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sd = random.randint(0,99999999)\n",
        "print(sd)\n",
        "\n",
        "np.random.seed(sd)\n",
        "random.seed(sd)\n",
        "os.environ['PYTHONHASHSEED']=str(sd)\n",
        "\n",
        "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "tf.set_random_seed(sd)\n",
        "\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
        "K.set_session(sess)\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWMiX5eCja3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def now():\n",
        "    return datetime.now().isoformat()[5:-7].replace('T',' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vMYQkt7r8m",
        "colab_type": "text"
      },
      "source": [
        "### 1-3. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2arA7qSIgtGt",
        "colab_type": "code",
        "outputId": "45b56187-2e83-41de-df2b-aae624526578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "#os.chdir('/content/gdrive/My Drive/Colab Notebooks/smishing/') \n",
        "train = pd.read_csv('0_Data/train.csv')\n",
        "print(train.shape)\n",
        "train.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(295945, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year_month</th>\n",
              "      <th>text</th>\n",
              "      <th>smishing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id year_month                                               text  smishing\n",
              "0   0    2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
              "1   1    2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
              "2   2    2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR6rYpgo3ubq",
        "colab_type": "text"
      },
      "source": [
        "## 2. 데이터 전처리\n",
        "### 2-1. Data Cleaning\n",
        "- Mecab을 이용하여 텍스트를 정제합니다.\n",
        "    - 영문은 소문자화하고 한글, 영문 제외 모두 제거하였습니다.\n",
        "    - 영문 중 xxx 등으로 비식별처리된 것은 모두 제거하였습니다.\n",
        "- Bi-gram을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDG7diik76t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(text_list):\n",
        "    '''\n",
        "    text cleaning\n",
        "    args: text list that wants to tokenize\n",
        "    return: bigram list\n",
        "    '''\n",
        "    stopwords = ['을', '를', '이', '가', '은', '는', 'null'] # 제거: 불용어, 한글 영문 외 문자, XXX 등 비식별처리된 문자\n",
        "    tokenizer = Mecab()\n",
        "    bigram_list = []\n",
        "    for text in text_list:\n",
        "        txt = re.sub('[^가-힣a-z]',' ',text.lower())\n",
        "        txt = re.sub('x{1,}',' ',txt)\n",
        "        token = tokenizer.morphs(txt)  # tokenizing\n",
        "        token = [t for t in token if t not in stopwords or type(t)!= float] # text cleaning\n",
        "        bigram = [token[i]+'.'+token[i+1] for i in range(len(token)-1)]  # bi-gram\n",
        "        bigram_list.append(' '.join(bigram))\n",
        "    return bigram_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJRpzMtr8NHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['bigram'] = text_preprocessing(train.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBqAVONG-PBo",
        "colab_type": "text"
      },
      "source": [
        "### 2-2. Data Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-gbA3iJ0neA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "Counter(train['smishing'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdFKHQqh0va_",
        "colab_type": "text"
      },
      "source": [
        "- Counter({0: 277242, 1: 18703})으로 6.31975535994864%의 비율만이 스미싱 문자임을 알 수 있습니다.\n",
        "- 즉, 데이터 불균형 문제(Data Imbalance Problem)가 발생하였습니다.\n",
        "- 따라서 데이터를 혼합하여 샘플링하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itgYwhhGBzzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_data_sampling(train, seed=1234, a=3, b=3):\n",
        "    '''\n",
        "    Args: train data, seed number, a(under sampling), b(over sampling)\n",
        "    Return: sampling index\n",
        "    '''\n",
        "    train_nsm_idx=list(train[train['smishing']==0].index)\n",
        "    train_sm_idx=list(train[train['smishing']==1].index)\n",
        "    random.seed(seed)\n",
        "    train_nsm_idx = random.sample(train_nsm_idx, k=18703*a)\n",
        "    random.seed(seed)\n",
        "    train_sm_idx = random.choices(train_sm_idx, k=18703*b)\n",
        "    train_idx = train_nsm_idx + train_sm_idx\n",
        "    print(train_idx[:5])\n",
        "    random.shuffle(train_idx)\n",
        "    print(train_idx[:5])\n",
        "    return train_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvFIOD9HBY3T",
        "colab_type": "code",
        "outputId": "7306fa4f-a836-44d2-81a6-c76e1238c9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "trn_idx = train_data_sampling(train, seed=sd, a=3, b=2)\n",
        "df_train = train.iloc[trn_idx].reset_index(drop=True)\n",
        "print(df_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[206864, 218560, 111768, 152524, 170588]\n",
            "[25559, 185452, 293634, 175839, 247866]\n",
            "(93515, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNLLwnt1bCm-",
        "colab_type": "text"
      },
      "source": [
        "### 2-3. text pre-processing\n",
        "- 모델을 학습하기 위해 텍스트 데이터를 시퀀스 데이터로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pYUYKgCEpj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_tokenizer(tokenizer):\n",
        "    mname = 'tokenizer_'+now()\n",
        "    with open('1_Model/'+mname+'.pickle', 'wb') as f:\n",
        "        pickle.dump(tokenizer, f, protocol = pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtzQUkXSB4oC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text2sequence(train_text, max_len=1000):\n",
        "    '''\n",
        "    transform text to sequence\n",
        "    Args: text of train data, max length(for word embedding)\n",
        "    Return: train data(for modeling), vocabulary size\n",
        "    '''\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(train_text)\n",
        "    save_tokenizer(tokenizer)\n",
        "    train_X_seq = tokenizer.texts_to_sequences(train_text)\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    print('vocab size: ', vocab_size)\n",
        "    X_train = pad_sequences(train_X_seq, maxlen=max_len)\n",
        "    return X_train, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuGsuVebewK3",
        "colab_type": "code",
        "outputId": "3763a0c3-d2a0-49e9-d556-483309eafbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_y = df_train['smishing']\n",
        "train_X, vocab_size = text2sequence(df_train['bigram'], max_len=660)\n",
        "print(train_X.shape, train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size:  22614\n",
            "vocab size:  22614\n",
            "(93515, 660) (93515,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua9JfvszX407",
        "colab_type": "text"
      },
      "source": [
        "## 3. 탐색적 자료 분석 (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onDiYpU31eJ5",
        "colab_type": "text"
      },
      "source": [
        "- 위의 max_len을 정하기 위해 EDA를 하여 적당한 len을 결정하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJ3o6Te4jrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([len(x.split()) for x in train['bigram']]).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNsXkyJMhmhB",
        "colab_type": "text"
      },
      "source": [
        "## 4. 변수 선택 및 모델 구축\n",
        "### Build Model\n",
        "- 모델 평가 지표는 AUC입니다.\n",
        "- 모델은 Bi-LSTM (Bi-Directional Long Short Term Memory)을 사용하였습니다.\n",
        "- 텍스트는 Bi-gram을 sequence로 변환한 데이터로 학습하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY49FyLN39Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auc_ = 0\n",
        "def auc_score(y_true, y_pred):\n",
        "    global auc_\n",
        "    try:\n",
        "        auc_ = roc_auc_score( y_true, y_pred, average='macro', sample_weight = None).astype('float32')\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return auc_\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    score = tf.py_func( lambda y_true, y_pred : auc_score(y_true, y_pred) , [y_true, y_pred], 'float32', stateful = False, name = 'sklearnAUC' )\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kCh0a2eLFxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BiLSTM(vocab_size, max_len=1000):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 128, input_length = max_len))\n",
        "    model.add(SpatialDropout1D(0.3))\n",
        "    model.add(Bidirectional(LSTM(64)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='tanh', kernel_regularizer = regularizers.l2(0.001)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpJnBvgClEhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_save(model, mname):\n",
        "    model_json = model.to_json()\n",
        "    with open('1_Model/'+mname+'.json', 'w') as json_file : \n",
        "        json_file.write(model_json)\n",
        "    model.save_weights('1_Model/'+mname+'.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqwq_3Rmh5e2",
        "colab_type": "text"
      },
      "source": [
        "## 5. 모델 학습 및 검증\n",
        "- 모델을 학습합니다.\n",
        "- EarlyStopping으로 과도한 학습을 하지 않고 적당한 score에 도달하면 조기종료 할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fULSvCnRmfep",
        "colab_type": "code",
        "outputId": "1e552434-38a9-4262-beb3-01597ef773f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "print('START TIME: ', datetime.now().isoformat())\n",
        "model = BiLSTM(vocab_size, max_len=660)\n",
        "early_stopping = EarlyStopping(patience=3, min_delta=0.00001)\n",
        "history = model.fit(train_X2, train_y, epochs=50, batch_size=128, validation_split=0.3, callbacks=[early_stopping])\n",
        "\n",
        "mname = now()+'_BiLSTM_bigram'\n",
        "model_save(model, mname)\n",
        "print('END TIME: ', datetime.now().isoformat())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "START TIME:  2020-01-17T12:10:54.752534\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 660, 128)          2894592   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 660, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,001,729\n",
            "Trainable params: 3,001,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 65460 samples, validate on 28055 samples\n",
            "Epoch 1/50\n",
            "65460/65460 [==============================] - 2077s 32ms/sample - loss: 0.0547 - auc: 0.9966 - val_loss: 0.0060 - val_auc: 1.0000\n",
            "Epoch 2/50\n",
            "65460/65460 [==============================] - 2064s 32ms/sample - loss: 0.0034 - auc: 1.0000 - val_loss: 0.0028 - val_auc: 1.0000\n",
            "Epoch 3/50\n",
            "65460/65460 [==============================] - 2060s 31ms/sample - loss: 0.0054 - auc: 0.9999 - val_loss: 0.0035 - val_auc: 1.0000\n",
            "Epoch 4/50\n",
            "65460/65460 [==============================] - 2063s 32ms/sample - loss: 0.0026 - auc: 1.0000 - val_loss: 0.0054 - val_auc: 1.0000\n",
            "Epoch 5/50\n",
            "65460/65460 [==============================] - 2070s 32ms/sample - loss: 0.0022 - auc: 1.0000 - val_loss: 0.0019 - val_auc: 1.0000\n",
            "Epoch 6/50\n",
            "65460/65460 [==============================] - 2041s 31ms/sample - loss: 0.0043 - auc: 0.9999 - val_loss: 0.0332 - val_auc: 0.9999\n",
            "Epoch 7/50\n",
            "65460/65460 [==============================] - 1903s 29ms/sample - loss: 0.0072 - auc: 0.9999 - val_loss: 0.0026 - val_auc: 1.0000\n",
            "Epoch 8/50\n",
            "65460/65460 [==============================] - 1860s 28ms/sample - loss: 0.0014 - auc: 1.0000 - val_loss: 0.0017 - val_auc: 1.0000\n",
            "Epoch 9/50\n",
            "65460/65460 [==============================] - 1845s 28ms/sample - loss: 0.0014 - auc: 1.0000 - val_loss: 0.0026 - val_auc: 1.0000\n",
            "Epoch 10/50\n",
            "65460/65460 [==============================] - 1833s 28ms/sample - loss: 0.0014 - auc: 1.0000 - val_loss: 0.0019 - val_auc: 1.0000\n",
            "Epoch 11/50\n",
            "55040/65460 [========================>.....] - ETA: 4:28 - loss: 8.2333e-04 - auc: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGAGjhDqzn9a",
        "colab_type": "text"
      },
      "source": [
        "## 6. 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5__SCgYPVPqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text2sequence_test(tokenizer, test_text, max_len=1000):\n",
        "    test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "    X_test = pad_sequences(test_seq, maxlen=max_len)\n",
        "    return X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nBWa9Njzyzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(test_file_path):\n",
        "    '''\n",
        "    Args: String\n",
        "    Return: Pandas DataFrame    \n",
        "    '''\n",
        "    \n",
        "    '''1. 테스트 파일 불러오기'''\n",
        "    test = pd.read_csv(test_file_path)\n",
        "    \n",
        "    '''2. 모델 불러오기'''\n",
        "    with open('1_Model/tokenizer.pickle', 'rb') as f:\n",
        "        tokenizer_test = pickle.load(f)\n",
        "\n",
        "    with open('1_Model/model.json', 'r') as ff:\n",
        "        json_model = ff.read()\n",
        "    model_test = model_from_json(json_model)\n",
        "    model_test.load_weights('1_Model/model.h5')\n",
        "    \n",
        "    '''3. 예측 전 필요한 사항 진행하기'''\n",
        "    test['bigram'] = text_preprocessing(test.text)\n",
        "    test_X = text2sequence_test(tokenizer_test, test['bigram'], max_len=660)\n",
        "    \n",
        "    model_test.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc])\n",
        "\n",
        "    '''4. 예측 진행하기'''\n",
        "    y_pred = model_test.predict(test_X, batch_size=128)\n",
        "    \n",
        "    '''5. 예측치 데이터프레임에 합치기'''\n",
        "    test['smishing'] = y_pred\n",
        "    submission = test[['id','smishing']]\n",
        "    #submission.to_csv('submission.csv',index=False)\n",
        "\n",
        "    return submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrDeLGrtz0gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = get_prediction('0_Data/public_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}