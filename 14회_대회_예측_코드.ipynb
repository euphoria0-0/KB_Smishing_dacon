{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14회_대회_예측_코드.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/euphoria96/KB_Smishing_dacon/blob/master/14%ED%9A%8C_%EB%8C%80%ED%9A%8C_%EC%98%88%EC%B8%A1_%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU8TE6MvgKLJ",
        "colab_type": "text"
      },
      "source": [
        "## Dacon 14회 KB 금융문자 분석 모델링 경진대회\n",
        "### euphoria\n",
        "### 2020년 1월 17일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0T35SVtgHaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts6LDB8S3gG1",
        "colab_type": "code",
        "outputId": "e0b6f6ca-d6ee-4cec-e3fd-27615cc9f668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Colab Notebooks/smishing/Mecab-ko-for-Google-Colab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/smishing/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwo8qNZs3gsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnBsm5b820wD",
        "colab_type": "text"
      },
      "source": [
        "## 1. 필요한 패키지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOY7wsx_LKCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessing\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import pickle\n",
        "# text tokenizing\n",
        "import re\n",
        "from konlpy.tag import Mecab\n",
        "# modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, SpatialDropout1D, Dropout\n",
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import roc_auc_score\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mi4ICRpS4J",
        "colab_type": "text"
      },
      "source": [
        "## 2. get_prediction\n",
        "1. 이 함수는 테스트에 해당하는 csv 파일 경로를 매개변수로 가집니다.\n",
        "2. 이 함수는 미리 만들어진 모델을 불러와 예측을 수행합니다.\n",
        "3. 이 함수는 예측치를 불러온 csv 파일에 넣습니다. 이 때 예측치에 해당하는 column name은 smishing 입니다.\n",
        "4. 이 함수는 데이터프레임을 리턴합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CytPZaPiwUnF",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(text_list):\n",
        "    stopwords = ['을', '를', '이', '가', '은', '는', 'null']\n",
        "    tokenizer = Mecab()\n",
        "    token_list, ngram2_list = [], []\n",
        "    for text in text_list:\n",
        "        txt = re.sub('[^가-힣a-z]',' ',text.lower())\n",
        "        txt = re.sub('x{1,}',' ',txt)\n",
        "        token = tokenizer.morphs(txt)\n",
        "        token = [t for t in token if t not in stopwords or type(t)!= float]\n",
        "        token_list.append(' '.join(token))\n",
        "        ngram2 = [token[i]+'.'+token[i+1] for i in range(len(token)-1)]\n",
        "        ngram2_list.append(' '.join(ngram2))\n",
        "    return token_list, ngram2_list\n",
        "\n",
        "def text2sequence_test(tokenizer, test_text, max_len=1000):\n",
        "    test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "    X_test = pad_sequences(test_seq, maxlen=max_len)\n",
        "    return X_test\n",
        "\n",
        "auc_ = 0\n",
        "def auc_score(y_true, y_pred):\n",
        "    global auc_\n",
        "    try:\n",
        "        auc_ = roc_auc_score( y_true, y_pred, average='macro', sample_weight = None).astype('float32')\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return auc_\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    score = tf.py_func( lambda y_true, y_pred : auc_score(y_true, y_pred) , [y_true, y_pred], 'float32', stateful = False, name = 'sklearnAUC' )\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w167m4dgpSZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(test_file_path):\n",
        "    '''\n",
        "    Args: String\n",
        "    Return: Pandas DataFrame    \n",
        "    '''\n",
        "    \n",
        "    '''1. 테스트 파일 불러오기'''\n",
        "    test = pd.read_csv(test_file_path)\n",
        "    \n",
        "    '''2. 모델 불러오기'''\n",
        "    with open('1_Model/tokenizer_01-16 07:13:11.pickle', 'rb') as f:\n",
        "        tokenizer_test = pickle.load(f)\n",
        "\n",
        "    with open('1_Model/01-16 09:45:06_BiLSTM_bigram_660.json', 'r') as ff:\n",
        "        json_model = ff.read()\n",
        "    model_test = model_from_json(json_model)\n",
        "    model_test.load_weights('1_Model/01-16 09:45:06_BiLSTM_bigram_660.h5')\n",
        "    \n",
        "    '''3. 예측 전 필요한 사항 진행하기'''\n",
        "    test['token_txt'], test['bigram'] = text_preprocessing(test.text)\n",
        "    test_X = text2sequence_test(tokenizer_test, test['token_txt'], max_len=660)\n",
        "    test_X2 = text2sequence_test(tokenizer_test, test['bigram'], max_len=660)\n",
        "    \n",
        "    model_test.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc])\n",
        "\n",
        "    '''4. 예측 진행하기'''\n",
        "    y_pred = model_test.predict(test_X2, batch_size=128)\n",
        "    \n",
        "    '''5. 예측치 데이터프레임에 합치기'''\n",
        "    test['smishing'] = y_pred\n",
        "    submission = test[['id','smishing']]\n",
        "    #submission.to_csv('submission.csv',index=False)\n",
        "\n",
        "    return submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXchsbnhpSdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/smishing/')\n",
        "y_pred = get_prediction('0_Data/public_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}